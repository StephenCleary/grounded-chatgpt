@page "/baseline"
@using Azure.AI.OpenAI;
@using Microsoft.Extensions.Options;
@inject OpenAIClient OpenAIClient
@inject CostTracker CostTracker
@inject IOptions<OpenAIOptions> OpenAIOptions

<PageTitle>Baseline</PageTitle>

<h1>Out-of-the-box ChatGPT (3.5-turbo) Chat</h1>

<InputTextArea @bind-Value="Prompt" />

<button class="btn btn-primary" @onclick="SubmitAsync">Submit</button>

<h2>Response:</h2>
<p>@Response</p>

<h2>Stats</h2>
<p>Prompt tokens: @PromptTokenUsage; completion tokens: @CompletionTokenUsage; total tokens: @TotalTokenUsage; cost: $@Cost</p>
<p>Finish reason: @FinishReason</p>

@code {
	private string Prompt { get; set; } = "";
	private string Response { get; set; } = "";
	private int PromptTokenUsage { get; set; }
	private int CompletionTokenUsage { get; set; }
	private int TotalTokenUsage { get; set; }
	private decimal Cost { get; set; }
	private string FinishReason { get; set; } = "";

	private async Task SubmitAsync()
	{
		// Just shoot it off to ChatGPT.

		var chatResponse = await OpenAIClient.GetChatCompletionsAsync(
			deploymentOrModelName: OpenAIOptions.Value.ChatDeployment,
			new ChatCompletionsOptions()
			{
				Messages =
				{
					new ChatMessage(ChatRole.User, Prompt),
				},
				Temperature = (float)0.7,
				MaxTokens = 800,
				NucleusSamplingFactor = (float)0.95,
				FrequencyPenalty = 0,
				PresencePenalty = 0,
			});
		var chatCompletions = chatResponse.Value;
		(PromptTokenUsage, CompletionTokenUsage, TotalTokenUsage) = (chatCompletions.Usage.PromptTokens, chatCompletions.Usage.CompletionTokens, chatCompletions.Usage.TotalTokens);
		Cost = 0.002M / 1000M * TotalTokenUsage;
		var choice = chatCompletions.Choices.FirstOrDefault();
		if (choice == null)
		{
			Response = "{No choices returned.}";
			await CostTracker.AddAsync(Cost);
			return;
		}

		FinishReason = choice.FinishReason;
		Response = $"{choice.Message.Role.Label}: {choice.Message.Content}";

		await CostTracker.AddAsync(Cost);
	}
}
